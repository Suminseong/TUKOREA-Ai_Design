K-means 하겠다

클러스터링 하겠구만

비지도 학습이란?

패턴(임의의 점을 찍고 그 점까지의 거리가 가까운 군집을 고르는 패턴으로 생각하면 좋다)

이전에 배운 것과는 달리 라벨링을 하지 않음.

우옹애

Affinity Diagram과 유사하다...

K-Means?

군집화 알고리즘. 라벨링 없는 샘플을 K개의 군집의 가장 가까운 평균으로 모아줌.
이때, 군집의 수는 정해져 있어야 함.(K개)

클러스터로 묶을 때, 클러스터 중점(Centroid였나 암튼)에 가까운 군집으로 묶는다~

1/Nk {Sum}(xi)

손실함수는 SSE를 쓴다. 군집 중심과의 거리를 측정하는데, 제곱오차를 합한다. 제곱평균과는 다르쥬

중점까지의 거리가 가깝게 분류되었다 = 손실제곱합이 작다 = 분류가 이쁘다

거리 기반이기 때문에 거리의 합을 쓴다~

Algorithm flow

1. K개의 샘플을 골라 초기 중심점을 잡는다.
2. 나머지 샘플들을 가장 가까운 친구 하나에게 묶는다.
3. 중심점 위치를 갱신한다.(클러스터의 중점에 가장 가까운 샘플로 재설정)
4. 바뀐 중심점의 위치를 따라 샘플을 재배치. 그리고 반복
5. 손실함수가 수렴한다.

K-Means의 평가

군집 수 K가 얼마가 최적화인가는 엘보우 method를 쓴다.

SSE 손실함수가 꺾이는 지점(엘보우)을 찾으면 된다. K 대입은 그냥 많이 해보면 된다.

-> 얘는 쉽다. 그리고 너무 간단하다

EM Algorithm?

K-Means보다 복잡하게.

군집할당을 확률적으로 진행한다. 할당에 관대하다는 의미.(Soft Clustering)

샘플 a가 클러스터 A일 확률은 0.6, B일 확률은 0.3 이런 식으로 분류된다. K-means는 그런거 없다!

여러모로 K-Means 상위호환. 몰론, 확률을 배제할 때는 K-Means 씀. 

